{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnGfZwuDdN4Y"
      },
      "source": [
        "# <center> </center>\n",
        "# <center> **Computer Vision** </center>\n",
        "# <center> **Portfolio Exam 1**</center>\n",
        "# <center>**Object Detection for Wildlife Conservation - Detecting Waterfowl in UAV Thermal Imagery**</center>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7UgZc1EdsLD"
      },
      "source": [
        "**Submitted by:**\n",
        "****\n",
        "\n",
        "*   **Riya Biju - 10000742**\n",
        "*   **Harsha Sathish - 10001000**\n",
        "*   **Harshith Babu Prakash Babu - 10001191**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1qO1rfTd9D-"
      },
      "source": [
        "**Assignment 1: Object Detection for Wildlife Conservation - Detecting\n",
        "Waterfowl in UAV Thermal Imagery (15 Points)**\n",
        "\n",
        "Unmanned Aerial Vehicles (UAVs, or drones) are increasingly used in wildlife conservation\n",
        "for non-invasive monitoring of animal populations. They enable researchers to capture aerial\n",
        "imagery that supports automated species detection and population estimation.\n",
        "In this assignment, you will develop and evaluate an object detection model for identifying\n",
        "waterfowl (aquatic birds) in aerial images. You will use the UAV-derived Waterfowl Thermal\n",
        "Imagery Dataset1\n",
        ", which includes both thermal and RGB images of wetlands with annotated\n",
        "bounding boxes around individual birds.\n",
        "1 https://data.mendeley.com/datasets/46k66mz9sz/2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgV80IUEeTP1"
      },
      "source": [
        "# **1. Importing all necessary python modules**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0JkM7P5sdIlv"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ Libraries imported successfully\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from ultralytics import YOLO\n",
        "import torch\n",
        "import pandas as pd\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "\n",
        "print(\"âœ“ Libraries imported successfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "far7U0aBklpB"
      },
      "source": [
        "# **2. Configuration and Repository Structure**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "NGsSsBcnkvxp"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ Configuration set\n",
            "  Data root: /Users/harshasathish/Desktop/MAI/ComputerVision/Portfolio1_new\n",
            "  Output root: output\n",
            "\n",
            "âœ“ Cleaning old output directories...\n",
            "âœ“ Directory structure initialized\n"
          ]
        }
      ],
      "source": [
        "DATA_ROOT = '/Users/harshasathish/Desktop/MAI/ComputerVision/Portfolio1_new'\n",
        "OUTPUT_ROOT = 'output'\n",
        "\n",
        "# Training hyperparameters\n",
        "EPOCHS = 100\n",
        "IMG_SIZE = 640\n",
        "BATCH_SIZE = 8\n",
        "TRAIN_RATIO = 0.7\n",
        "VAL_RATIO = 0.15\n",
        "TEST_RATIO = 0.15\n",
        "\n",
        "print(f\"âœ“ Configuration set\")\n",
        "print(f\"  Data root: {DATA_ROOT}\")\n",
        "print(f\"  Output root: {OUTPUT_ROOT}\")\n",
        "\n",
        "data_root = Path(DATA_ROOT)\n",
        "output_root = Path(OUTPUT_ROOT)\n",
        "output_root.mkdir(exist_ok=True)\n",
        "\n",
        "# Create directory structure\n",
        "yolo_root = output_root / 'yolo_dataset'\n",
        "model_dir = output_root / 'models'\n",
        "results_dir = output_root / 'results'\n",
        "\n",
        "print(\"\\nâœ“ Cleaning old output directories...\")\n",
        "# Clean and create output directories\n",
        "for d in [yolo_root, model_dir, results_dir]:\n",
        "    if d.exists():\n",
        "        print(f\"  Removing {d}\")\n",
        "        shutil.rmtree(d)\n",
        "    d.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(f\"âœ“ Directory structure initialized\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBdf3DQjlJFj"
      },
      "source": [
        "# **3. Load and validate Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ANnzjvdqlP7-"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "STEP 1: Dataset Preparation\n",
            "============================================================\n",
            "\n",
            "âœ“ Reading annotations from CSV...\n",
            "âœ“ Found 8975 annotations in CSV\n",
            "âœ“ CSV columns: ['imageFilename', 'x(column)', 'y(row)', 'width', 'height']\n",
            "\n",
            "âœ“ Found 355 thermal images (.tif)\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STEP 1: Dataset Preparation\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Define paths\n",
        "positive_img_dir = data_root / 'thermal_Images' / '01_Positive_img'\n",
        "negative_img_dir = data_root / 'thermal_Images' / '03_Negative'\n",
        "annotation_dir = data_root / 'thermal_Images' / '02_Positive_annotation'\n",
        "csv_path = annotation_dir / 'Bounding Box Label.csv'\n",
        "\n",
        "# Check if paths exist\n",
        "if not positive_img_dir.exists():\n",
        "    raise FileNotFoundError(f\"Image directory not found: {positive_img_dir}\")\n",
        "if not negative_img_dir.exists():\n",
        "    raise FileNotFoundError(f\"Negative Image directory not found: {negative_img_dir}\")\n",
        "if not csv_path.exists():\n",
        "    raise FileNotFoundError(f\"CSV file not found: {csv_path}\")\n",
        "\n",
        "# Read CSV annotations\n",
        "print(f\"\\nâœ“ Reading annotations from CSV...\")\n",
        "df = pd.read_csv(csv_path)\n",
        "print(f\"âœ“ Found {len(df)} annotations in CSV\")\n",
        "\n",
        "# Get all .tif image files (Positive AND Negative)\n",
        "positive_files = list(positive_img_dir.glob('*.tif'))\n",
        "negative_files = list(negative_img_dir.glob('*.tif'))\n",
        "\n",
        "print(f\"\\nâœ“ Found {len(positive_files)} positive thermal images\")\n",
        "print(f\"âœ“ Found {len(negative_files)} negative thermal images\")\n",
        "\n",
        "# Combine all images\n",
        "all_image_files = positive_files + negative_files\n",
        "print(f\"âœ“ Total dataset size: {len(all_image_files)} images\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXG3vG5wlUSW"
      },
      "source": [
        "# **4. Create annotations dictionary**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ERNFUQf2lbjm"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ Found annotations for 355 unique images\n",
            "âœ“ Found 355 images with annotations\n"
          ]
        }
      ],
      "source": [
        "annotations_dict = {}\n",
        "# Group annotations by image filename\n",
        "for _, row in df.iterrows():\n",
        "    img_name = row['imageFilename']\n",
        "    if img_name not in annotations_dict:\n",
        "        annotations_dict[img_name] = []\n",
        "    annotations_dict[img_name].append(row)\n",
        "\n",
        "print(f\"âœ“ Found annotations for {len(annotations_dict)} unique images\")\n",
        "\n",
        "# Filter images that have annotations\n",
        "valid_images = []\n",
        "for img_path in image_files:\n",
        "    if img_path.name in annotations_dict:\n",
        "        valid_images.append(img_path)\n",
        "\n",
        "print(f\"âœ“ Found {len(valid_images)} images with annotations\")\n",
        "\n",
        "# Check if we have matching data\n",
        "if len(valid_images) == 0:\n",
        "    print(\"\\nâš  WARNING: No matching images found!\")\n",
        "    print(\"Sample annotation filenames:\")\n",
        "    for name in list(annotations_dict.keys())[:5]:\n",
        "        print(f\"  - {name}\")\n",
        "    print(\"\\nSample image filenames:\")\n",
        "    for img in image_files[:5]:\n",
        "        print(f\"  - {img.name}\")\n",
        "    raise ValueError(\"No images match the annotations in the CSV\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YhM7R_KlepA"
      },
      "source": [
        "# **5. Split Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Ku4d7KbmljoQ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "âœ“ Dataset split:\n",
            "  Training:   248 images (70%)\n",
            "  Validation: 53 images (15%)\n",
            "  Test:       54 images (15%)\n"
          ]
        }
      ],
      "source": [
        "# First split: train vs temp (val+test)\n",
        "train_imgs, temp_imgs = train_test_split(\n",
        "    valid_images,\n",
        "    test_size=(VAL_RATIO + TEST_RATIO),\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Second split: val vs test\n",
        "val_imgs, test_imgs = train_test_split(\n",
        "    temp_imgs,\n",
        "    test_size=TEST_RATIO/(VAL_RATIO + TEST_RATIO),\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(f\"\\nâœ“ Dataset split:\")\n",
        "print(f\"  Training:   {len(train_imgs)} images ({TRAIN_RATIO*100:.0f}%)\")\n",
        "print(f\"  Validation: {len(val_imgs)} images ({VAL_RATIO*100:.0f}%)\")\n",
        "print(f\"  Test:       {len(test_imgs)} images ({TEST_RATIO*100:.0f}%)\")\n",
        "\n",
        "splits = {\n",
        "    'train': train_imgs,\n",
        "    'val': val_imgs,\n",
        "    'test': test_imgs\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U8RNQylOlmVX"
      },
      "source": [
        "# **6. Process and convert Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "xTbcj3VAltW5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "âœ“ Clearing old dataset directories...\n",
            "\n",
            "âœ“ Processing train set...\n",
            "  Processed 248 images\n",
            "\n",
            "âœ“ Processing val set...\n",
            "  Processed 53 images\n",
            "\n",
            "âœ“ Processing test set...\n",
            "  Processed 54 images\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nâœ“ Clearing old dataset directories...\")\n",
        "# Remove old split directories\n",
        "for split_name in splits:\n",
        "    split_dir = yolo_root / split_name\n",
        "    if split_dir.exists():\n",
        "        print(f\"  Removing {split_dir}\")\n",
        "        shutil.rmtree(split_dir)\n",
        "\n",
        "# Process each split\n",
        "for split_name, img_list in splits.items():\n",
        "    # Create directories\n",
        "    img_dir = yolo_root / split_name / 'images'\n",
        "    label_dir = yolo_root / split_name / 'labels'\n",
        "    img_dir.mkdir(parents=True, exist_ok=True)\n",
        "    label_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    print(f\"\\nâœ“ Processing {split_name} set...\")\n",
        "\n",
        "    # Process each image\n",
        "    for img_path in img_list:\n",
        "        # Read thermal image\n",
        "        img = cv2.imread(str(img_path), cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        if img is None:\n",
        "            print(f\"  âš  Warning: Could not read {img_path.name}\")\n",
        "            continue\n",
        "\n",
        "        img_height, img_width = img.shape\n",
        "\n",
        "        # Convert to RGB (3-channel)\n",
        "        img_rgb = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
        "\n",
        "        # Save converted image\n",
        "        dest_img = img_dir / img_path.name\n",
        "        cv2.imwrite(str(dest_img), img_rgb)\n",
        "\n",
        "        # Get annotations for this image\n",
        "        annotations = annotations_dict[img_path.name]\n",
        "\n",
        "        yolo_annotations = []\n",
        "        invalid_count = 0\n",
        "\n",
        "        # Convert each annotation to YOLO format\n",
        "        for ann in annotations:\n",
        "            # Get bounding box in pixel coordinates from CSV\n",
        "            x1_px = float(ann['x(column)'])\n",
        "            y1_px = float(ann['y(row)'])\n",
        "            w_px = float(ann['width'])\n",
        "            h_px = float(ann['height'])\n",
        "\n",
        "            # Skip boxes with zero or negative dimensions\n",
        "            if w_px <= 0 or h_px <= 0:\n",
        "                invalid_count += 1\n",
        "                continue\n",
        "\n",
        "            # Calculate x2, y2 in pixels\n",
        "            x2_px = x1_px + w_px\n",
        "            y2_px = y1_px + h_px\n",
        "\n",
        "            # Clip pixel coordinates to image boundaries\n",
        "            x1_clipped = max(0.0, x1_px)\n",
        "            y1_clipped = max(0.0, y1_px)\n",
        "            x2_clipped = min(float(img_width), x2_px)\n",
        "            y2_clipped = min(float(img_height), y2_px)\n",
        "\n",
        "            # Recalculate width/height from clipped coordinates\n",
        "            w_clipped = x2_clipped - x1_clipped\n",
        "            h_clipped = y2_clipped - y1_clipped\n",
        "\n",
        "            # Skip if box is now invalid\n",
        "            if w_clipped <= 0.001 or h_clipped <= 0.001:\n",
        "                invalid_count += 1\n",
        "                continue\n",
        "\n",
        "            # Convert to YOLO format (normalized coordinates)\n",
        "            x_center = (x1_clipped + w_clipped / 2) / img_width\n",
        "            y_center = (y1_clipped + h_clipped / 2) / img_height\n",
        "            norm_width = w_clipped / img_width\n",
        "            norm_height = h_clipped / img_height\n",
        "\n",
        "            # Class 0 for waterfowl\n",
        "            yolo_annotations.append(f\"0 {x_center:.6f} {y_center:.6f} {norm_width:.6f} {norm_height:.6f}\")\n",
        "\n",
        "        # Log filtered boxes for train set\n",
        "        if invalid_count > 0 and split_name == 'train':\n",
        "            print(f\"  âš  {img_path.name}: filtered {invalid_count} invalid boxes\")\n",
        "\n",
        "        # Save annotations if valid\n",
        "        if len(yolo_annotations) > 0:\n",
        "            dest_ann = label_dir / f\"{img_path.stem}.txt\"\n",
        "            with open(dest_ann, 'w') as f:\n",
        "                f.write('\\n'.join(yolo_annotations))\n",
        "        else:\n",
        "            # Skip this image if no valid annotations\n",
        "            if dest_img.exists():\n",
        "                dest_img.unlink()\n",
        "            if split_name != 'test':\n",
        "                print(f\"  âš  {img_path.name}: skipped (no valid annotations)\")\n",
        "\n",
        "    print(f\"  Processed {len(img_list)} images\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xg0Wj4FDl0h-"
      },
      "source": [
        "# **7. YOLO Configuration File**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Xfj8bsMxl5_w"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "âœ“ Dataset prepared successfully!\n",
            "  YOLO format saved to: output/yolo_dataset\n",
            "  Configuration: output/yolo_dataset/data.yaml\n"
          ]
        }
      ],
      "source": [
        "yaml_content = f\"\"\"# Waterfowl Detection Dataset\n",
        "path: {yolo_root.absolute()}\n",
        "train: train/images\n",
        "val: val/images\n",
        "test: test/images\n",
        "\n",
        "# Classes\n",
        "nc: 1\n",
        "names: ['waterfowl']\n",
        "\"\"\"\n",
        "\n",
        "yaml_path = yolo_root / 'data.yaml'\n",
        "with open(yaml_path, 'w') as f:\n",
        "    f.write(yaml_content)\n",
        "\n",
        "print(f\"\\nâœ“ Dataset prepared successfully!\")\n",
        "print(f\"  YOLO format saved to: {yolo_root}\")\n",
        "print(f\"  Configuration: {yaml_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpvn-Za-l-GZ"
      },
      "source": [
        "# **8. Validating Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "9F9PaEZwmDe7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "âœ“ Validating dataset...\n",
            "  train: 248 labels, 248 images.\n",
            "    - 6029 total boxes (from matching files).\n",
            "    - 0 empty label files.\n",
            "    - 0 line/format issues.\n",
            "  val: 53 labels, 53 images.\n",
            "    - 1295 total boxes (from matching files).\n",
            "    - 0 empty label files.\n",
            "    - 0 line/format issues.\n",
            "  test: 54 labels, 54 images.\n",
            "    - 1651 total boxes (from matching files).\n",
            "    - 0 empty label files.\n",
            "    - 0 line/format issues.\n",
            "\n",
            " All annotations are valid!\n"
          ]
        }
      ],
      "source": [
        "print(f\"\\nâœ“ Validating dataset...\")\n",
        "\n",
        "overall_issues = 0\n",
        "\n",
        "# Check each split\n",
        "for split in ['train', 'val', 'test']:\n",
        "    img_dir = yolo_root / split / 'images'\n",
        "    label_dir = yolo_root / split / 'labels'\n",
        "\n",
        "    if not img_dir.exists() or not label_dir.exists():\n",
        "        print(f\"  Skipping {split}: directory not found.\")\n",
        "        continue\n",
        "\n",
        "    # Get stems of all files\n",
        "    img_files = {p.stem for p in img_dir.glob('*.*') if p.suffix in ['.tif', '.jpg', '.png']}\n",
        "    label_files = {p.stem for p in label_dir.glob('*.txt')}\n",
        "\n",
        "    # Check for orphan labels\n",
        "    orphan_labels = label_files - img_files\n",
        "    if orphan_labels:\n",
        "        print(f\"  âš  {split}: Found {len(orphan_labels)} orphan label files (no matching image).\")\n",
        "        for orphan in list(orphan_labels)[:5]:\n",
        "            print(f\"    - {orphan}.txt\")\n",
        "        overall_issues += len(orphan_labels)\n",
        "\n",
        "    # Check for images without labels\n",
        "    background_images = img_files - label_files\n",
        "    if background_images:\n",
        "        print(f\"  â„¹ {split}: Found {len(background_images)} images with no labels (treated as backgrounds).\")\n",
        "\n",
        "    # Validate label content\n",
        "    issues_in_split = 0\n",
        "    total_boxes = 0\n",
        "    empty_files = 0\n",
        "\n",
        "    # Only check labels that have matching images\n",
        "    for label_stem in (label_files & img_files):\n",
        "        label_file = label_dir / f\"{label_stem}.txt\"\n",
        "\n",
        "        # Check for empty files\n",
        "        if label_file.stat().st_size == 0:\n",
        "            print(f\"  âš  {label_file.name}: FILE IS EMPTY (0 bytes).\")\n",
        "            issues_in_split += 1\n",
        "            empty_files += 1\n",
        "            continue\n",
        "\n",
        "        with open(label_file, 'r') as f:\n",
        "            lines = f.readlines()\n",
        "            if not lines:\n",
        "                print(f\"  âš  {label_file.name}: FILE IS EMPTY (no lines).\")\n",
        "                issues_in_split += 1\n",
        "                empty_files += 1\n",
        "                continue\n",
        "\n",
        "            # Validate each line\n",
        "            for line_num, line in enumerate(lines, 1):\n",
        "                line = line.strip()\n",
        "                if not line:\n",
        "                    continue\n",
        "\n",
        "                parts = line.split()\n",
        "                if len(parts) != 5:\n",
        "                    print(f\"  âš  {label_file.name} line {line_num}: wrong format (expected 5 parts, got {len(parts)})\")\n",
        "                    issues_in_split += 1\n",
        "                    continue\n",
        "\n",
        "                try:\n",
        "                    cls, x, y, w, h = map(float, parts)\n",
        "                    total_boxes += 1\n",
        "\n",
        "                    # Check if values are in valid range\n",
        "                    if not (0 <= x <= 1 and 0 <= y <= 1 and 0 < w <= 1 and 0 < h <= 1):\n",
        "                        print(f\"  âš  {label_file.name} line {line_num}: values out of range\")\n",
        "                        print(f\"    x={x:.3f}, y={y:.3f}, w={w:.3f}, h={h:.3f}\")\n",
        "                        issues_in_split += 1\n",
        "                except ValueError:\n",
        "                    print(f\"  âš  {label_file.name} line {line_num}: invalid values (not numbers)\")\n",
        "                    issues_in_split += 1\n",
        "\n",
        "    print(f\"  {split}: {len(label_files)} labels, {len(img_files)} images.\")\n",
        "    print(f\"    - {total_boxes} total boxes (from matching files).\")\n",
        "    print(f\"    - {empty_files} empty label files.\")\n",
        "    print(f\"    - {issues_in_split - empty_files} line/format issues.\")\n",
        "    overall_issues += issues_in_split\n",
        "\n",
        "# Final validation result\n",
        "if overall_issues > 0:\n",
        "    print(f\"\\n WARNING: Found {overall_issues} total annotation issues. Training may fail.\")\n",
        "else:\n",
        "    print(f\"\\n All annotations are valid!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "koHsyiGSmI6D"
      },
      "source": [
        "# **9. Training YOLO**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "HmKTN5demVUi"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "STEP 2: Model Training\n",
            "============================================================\n",
            "\n",
            "âœ“ Loading YOLOv8n (nano) pretrained model...\n",
            "\n",
            "âœ“ Starting training...\n",
            "  Epochs: 100\n",
            "  Image size: 640\n",
            "  Batch size: 8\n",
            "  Device: cpu\n",
            "New https://pypi.org/project/ultralytics/8.3.228 available ğŸ˜ƒ Update with 'pip install -U ultralytics'\n",
            "Ultralytics 8.3.227 ğŸš€ Python-3.13.2 torch-2.9.0 CPU (Apple M3 Pro)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=output/yolo_dataset/data.yaml, degrees=10, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=100, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=0.0, multi_scale=False, name=waterfowl_detector, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=output/models, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/Users/harshasathish/Desktop/MAI/ComputerVision/Portfolio1_new/output/models/waterfowl_detector, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
            "Model summary: 129 layers, 3,011,043 parameters, 3,011,027 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 5263.4Â±1638.6 MB/s, size: 316.9 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/harshasathish/Desktop/MAI/ComputerVision/Portfolio1_new/output/yolo_dataset/train/labels... 248 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 248/248 3.5Kit/s 0.1s\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /Users/harshasathish/Desktop/MAI/ComputerVision/Portfolio1_new/output/yolo_dataset/train/labels.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 5165.7Â±1729.4 MB/s, size: 323.7 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/harshasathish/Desktop/MAI/ComputerVision/Portfolio1_new/output/yolo_dataset/val/labels... 53 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 53/53 2.9Kit/s 0.0s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /Users/harshasathish/Desktop/MAI/ComputerVision/Portfolio1_new/output/yolo_dataset/val/labels.cache\n",
            "Plotting labels to /Users/harshasathish/Desktop/MAI/ComputerVision/Portfolio1_new/output/models/waterfowl_detector/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 0 dataloader workers\n",
            "Logging results to \u001b[1m/Users/harshasathish/Desktop/MAI/ComputerVision/Portfolio1_new/output/models/waterfowl_detector\u001b[0m\n",
            "Starting training for 100 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      1/100         0G      3.186      3.341     0.9406         83        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 1.1it/s 27.0s0.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.7it/s 5.7s2.8ss\n",
            "                   all         53       1295    0.00742     0.0911    0.00477    0.00113\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      2/100         0G      2.644      1.892     0.8628        101        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 1.2it/s 25.5s0.8ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.7it/s 5.7s2.8ss\n",
            "                   all         53       1295     0.0491      0.603     0.0641     0.0217\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      3/100         0G      2.465       1.78     0.8505        209        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 1.2it/s 25.6s0.8ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.7it/s 5.6s2.8ss\n",
            "                   all         53       1295    0.00145     0.0178    0.00573   0.000729\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      4/100         0G      2.602       1.64     0.8538        189        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 1.2it/s 26.5s0.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.7it/s 5.8s2.9ss\n",
            "                   all         53       1295     0.0334      0.394      0.121     0.0259\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      5/100         0G       2.67      1.614      0.862        187        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 1.2it/s 26.3s0.8ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.6it/s 6.4s3.2ss\n",
            "                   all         53       1295      0.595      0.389      0.388     0.0901\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      6/100         0G      2.352      1.422     0.8497        190        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 1.2it/s 25.6s0.8ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.7it/s 5.6s2.8ss\n",
            "                   all         53       1295      0.719      0.683      0.711      0.245\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      7/100         0G      2.335      1.343     0.8303        146        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 1.2it/s 26.5s0.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.7it/s 6.1s3.0ss\n",
            "                   all         53       1295      0.703      0.639      0.626      0.174\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      8/100         0G      2.299      1.304     0.8275         96        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 1.0it/s 31.9s0.8ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.6it/s 6.2s3.1ss\n",
            "                   all         53       1295      0.668      0.625      0.593      0.161\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      9/100         0G       2.12       1.16     0.8218        221        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 1.1it/s 28.9s0.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.7it/s 5.8s2.9ss\n",
            "                   all         53       1295      0.722      0.683      0.727      0.225\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     10/100         0G      2.104      1.115     0.8239        145        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 1.2it/s 26.2s0.8ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.7it/s 5.7s2.8ss\n",
            "                   all         53       1295      0.805      0.808      0.853      0.365\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     11/100         0G      2.312      1.224     0.8306        152        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 1.2it/s 25.9s0.8ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.7it/s 5.7s2.8ss\n",
            "                   all         53       1295      0.796      0.768      0.777      0.205\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     12/100         0G      2.202      1.145     0.8287        301        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 1.1it/s 28.1s0.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.7it/s 5.9s2.9ss\n",
            "                   all         53       1295      0.736      0.733      0.762      0.229\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     13/100         0G      2.026      1.053     0.8139        212        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 1.2it/s 25.9s0.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.7it/s 5.9s2.9ss\n",
            "                   all         53       1295      0.835      0.811      0.832      0.262\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     14/100         0G      2.098      1.031     0.8212        152        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 1.1it/s 27.2s0.8ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.7it/s 5.7s2.8ss\n",
            "                   all         53       1295      0.844      0.822      0.858      0.304\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     15/100         0G      1.981     0.9525     0.8164        194        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 1.2it/s 26.3s0.8ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.7it/s 5.6s2.8ss\n",
            "                   all         53       1295      0.818      0.769      0.827      0.314\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     16/100         0G       1.96     0.9544     0.8169        267        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 1.2it/s 25.9s0.8ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.7it/s 6.0s3.0ss\n",
            "                   all         53       1295      0.834      0.788      0.849      0.357\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     17/100         0G      1.993     0.9673     0.8177        184        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 1.1it/s 27.5s0.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.7it/s 5.8s2.9ss\n",
            "                   all         53       1295      0.875       0.86      0.875       0.31\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     18/100         0G      1.987     0.9329     0.8092        156        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 1.2it/s 26.4s0.8ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.7it/s 5.7s2.8ss\n",
            "                   all         53       1295       0.85      0.829      0.857      0.307\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     19/100         0G        1.9     0.8897     0.8068        150        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 1.2it/s 26.2s0.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.7it/s 5.6s2.8ss\n",
            "                   all         53       1295       0.83      0.796      0.823      0.275\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     20/100         0G      1.882     0.8844     0.8091        193        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 1.2it/s 25.8s0.8ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.7it/s 5.4s2.7ss\n",
            "                   all         53       1295      0.853      0.788      0.856      0.404\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     21/100         0G      1.886     0.8762     0.8129        332        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 1.2it/s 25.5s0.8ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.7it/s 5.6s2.8ss\n",
            "                   all         53       1295      0.869      0.829      0.867      0.321\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     22/100         0G      1.906     0.9054     0.8083        215        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 1.2it/s 25.8s0.8ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.7it/s 5.6s2.8ss\n",
            "                   all         53       1295      0.845      0.824      0.856      0.357\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     23/100         0G      1.879     0.8731     0.8179        115        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 1.2it/s 25.5s0.8ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.7it/s 5.6s2.8ss\n",
            "                   all         53       1295       0.87      0.846      0.881       0.36\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     24/100         0G      1.831     0.8294     0.8047        178        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 1.2it/s 25.6s0.8ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.7it/s 5.6s2.8ss\n",
            "                   all         53       1295      0.869      0.849      0.883      0.361\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     25/100         0G      1.751     0.8019     0.8036        223        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 1.2it/s 26.2s0.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.7it/s 5.6s2.8ss\n",
            "                   all         53       1295      0.886      0.886       0.91      0.426\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     26/100         0G       1.78     0.8423      0.814        141        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 1.2it/s 26.3s0.8ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.7it/s 5.5s2.7ss\n",
            "                   all         53       1295      0.855      0.858      0.901      0.429\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     27/100         0G      1.819     0.8293     0.8057        311        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 1.2it/s 25.9s0.8ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.7it/s 5.9s3.0ss\n",
            "                   all         53       1295      0.844      0.837      0.883      0.457\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     28/100         0G      1.838     0.8541     0.8069        155        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 1.1it/s 27.9s1.0ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.7it/s 6.1s3.0ss\n",
            "                   all         53       1295      0.839      0.847      0.865      0.362\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     29/100         0G      1.792     0.8002      0.805        217        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 1.1it/s 27.2s0.8ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.7it/s 5.7s2.8ss\n",
            "                   all         53       1295      0.866      0.835      0.888      0.453\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     30/100         0G        1.8     0.8072      0.812         61        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 1.2it/s 26.7s0.8ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.7it/s 5.6s2.8ss\n",
            "                   all         53       1295      0.844      0.849      0.883      0.396\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     31/100         0G      1.857     0.8183     0.8079        330        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 1.2it/s 26.5s0.8ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.7it/s 5.7s2.8ss\n",
            "                   all         53       1295      0.852      0.849      0.879      0.428\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     32/100         0G      1.869     0.8277     0.8132         98        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 1.2it/s 26.0s0.8ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.7it/s 5.6s2.8ss\n",
            "                   all         53       1295      0.892       0.88      0.904      0.346\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     33/100         0G      1.735     0.7945     0.8017        313        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 1.1it/s 27.1s1.0ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.6it/s 6.2s3.1ss\n",
            "                   all         53       1295      0.875      0.877      0.904      0.387\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     34/100         0G      1.748     0.7661     0.8037        226        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 1.1it/s 28.5s0.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.7it/s 5.6s2.8ss\n",
            "                   all         53       1295      0.884       0.85      0.899      0.395\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     35/100         0G      1.797     0.8035     0.8038        197        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 1.2it/s 26.7s0.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.7it/s 5.7s2.8ss\n",
            "                   all         53       1295      0.863      0.863      0.897      0.455\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     36/100         0G      1.724     0.7812     0.8024        321        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 1.2it/s 26.5s0.8ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.7it/s 5.6s2.8ss\n",
            "                   all         53       1295      0.856      0.831      0.893      0.467\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     37/100         0G      1.762     0.8032     0.7989        288        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 1.0it/s 30.6s0.8ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.7it/s 5.6s2.8ss\n",
            "                   all         53       1295      0.887      0.877      0.899      0.336\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     38/100         0G      1.744     0.7669     0.8025        170        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 1.2it/s 25.7s0.8ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.7it/s 5.6s2.8ss\n",
            "                   all         53       1295      0.899      0.882      0.912       0.33\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     39/100         0G       1.76     0.7614     0.8082        218        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 1.2it/s 26.5s0.8ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.7it/s 5.6s2.8ss\n",
            "                   all         53       1295      0.862      0.823      0.884      0.456\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     40/100         0G      1.736     0.7458     0.8019        154        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 1.1it/s 27.4s1.0ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.7it/s 5.8s2.9ss\n",
            "                   all         53       1295       0.88      0.857      0.899      0.435\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     41/100         0G      1.747      0.744     0.8055        118        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 1.1it/s 27.2s0.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.7it/s 5.5s2.7ss\n",
            "                   all         53       1295      0.892      0.874        0.9      0.461\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     42/100         0G      1.743     0.7477     0.8055        159        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 1.2it/s 26.8s0.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.7it/s 5.7s2.9ss\n",
            "                   all         53       1295      0.871      0.852      0.893      0.415\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     43/100         0G      1.664     0.7309     0.7962        200        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 1.2it/s 25.8s0.8ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.7it/s 5.6s2.8ss\n",
            "                   all         53       1295      0.872      0.854      0.901      0.471\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     44/100         0G      1.644     0.7077     0.8007        237        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 1.2it/s 26.2s0.8ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.7it/s 5.7s2.8ss\n",
            "                   all         53       1295      0.865      0.843      0.886      0.454\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     45/100         0G      1.664     0.7031     0.7942        136        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 1.2it/s 26.1s0.8ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.7it/s 5.6s2.8ss\n",
            "                   all         53       1295      0.872      0.829      0.884      0.447\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     46/100         0G      1.691     0.7143     0.8024        121        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 1.2it/s 25.9s0.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.7it/s 5.6s2.8ss\n",
            "                   all         53       1295        0.9      0.886      0.914      0.314\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     47/100         0G      1.666      0.746     0.7962         79        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 1.2it/s 25.9s0.8ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.7it/s 5.5s2.7ss\n",
            "                   all         53       1295      0.857      0.846      0.891      0.454\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     48/100         0G      1.734     0.7575     0.7981        161        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 1.2it/s 26.4s0.8ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.7it/s 5.6s2.7ss\n",
            "                   all         53       1295      0.873      0.877      0.908      0.449\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     49/100         0G      1.658     0.7131     0.7983        210        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 1.2it/s 25.4s0.8ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.7it/s 5.6s2.8ss\n",
            "                   all         53       1295      0.892      0.875       0.91      0.422\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     50/100         0G      1.674     0.7244     0.8011        180        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 1.2it/s 26.1s0.8ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.7it/s 5.6s2.8ss\n",
            "                   all         53       1295      0.891      0.886      0.914      0.457\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     51/100         0G      1.657     0.7095     0.7984        185        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 1.1it/s 28.6s0.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.7it/s 5.7s2.8ss\n",
            "                   all         53       1295      0.872      0.876      0.898       0.39\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     52/100         0G      1.656     0.7071     0.8009         91        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 1.2it/s 26.7s0.8ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.7it/s 5.6s2.8ss\n",
            "                   all         53       1295      0.911      0.896      0.929      0.442\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     53/100         0G       1.65     0.7352     0.7989        116        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 1.1it/s 28.0s0.8ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.7it/s 5.7s2.8ss\n",
            "                   all         53       1295      0.859      0.868      0.893      0.442\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     54/100         0G      1.583     0.6999     0.7958        138        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 1.1it/s 27.8s0.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.7it/s 6.0s3.0ss\n",
            "                   all         53       1295      0.881      0.871      0.902      0.489\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     55/100         0G      1.569     0.6878     0.7923        152        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 1.1it/s 27.5s0.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.7it/s 5.5s2.7ss\n",
            "                   all         53       1295      0.898      0.883      0.918      0.451\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     56/100         0G      1.608     0.6989     0.8018        186        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 1.2it/s 26.3s0.8ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.7it/s 5.6s2.8ss\n",
            "                   all         53       1295      0.897      0.865       0.91      0.479\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     57/100         0G      1.605     0.6994     0.7953        128        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 1.2it/s 26.2s0.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.7it/s 5.6s2.8ss\n",
            "                   all         53       1295      0.868      0.873      0.904      0.475\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     58/100         0G      1.553     0.6698      0.794        244        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 1.1it/s 27.5s0.8ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.7it/s 5.8s2.9ss\n",
            "                   all         53       1295       0.89       0.89      0.921      0.495\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     59/100         0G      1.581     0.6824     0.7901        138        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 1.2it/s 26.4s0.8ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.7it/s 5.8s2.9ss\n",
            "                   all         53       1295      0.893      0.887      0.927      0.521\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     60/100         0G      1.653     0.7344     0.7987        126        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 1.2it/s 26.7s0.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.6it/s 6.2s3.1ss\n",
            "                   all         53       1295       0.85      0.856      0.889      0.454\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     61/100         0G      1.623     0.7125     0.7866        133        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 1.1it/s 29.5s1.0ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.6it/s 6.2s3.0ss\n",
            "                   all         53       1295      0.909      0.896      0.934       0.52\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     62/100         0G      1.706      0.734     0.7965        174        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 1.1it/s 28.4s0.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.7it/s 5.6s2.8ss\n",
            "                   all         53       1295      0.872      0.869      0.902      0.473\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     63/100         0G      1.695     0.7173     0.7995        166        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 1.0it/s 30.0s1.1ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.6it/s 6.5s3.2ss\n",
            "                   all         53       1295      0.906      0.892      0.927      0.484\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     64/100         0G      1.689      0.708     0.8029         74        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 1.2it/s 26.1s0.8ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.7it/s 5.6s2.8ss\n",
            "                   all         53       1295      0.881      0.883      0.914      0.474\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     65/100         0G      1.583     0.6892     0.7938        141        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 1.2it/s 26.7s0.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.7it/s 5.8s2.9ss\n",
            "                   all         53       1295      0.895      0.891      0.925      0.501\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     66/100         0G      1.567     0.6931     0.7983        208        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 1.1it/s 27.4s1.0ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.7it/s 5.7s2.8ss\n",
            "                   all         53       1295      0.899      0.881      0.916      0.473\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     67/100         0G       1.58     0.6883     0.7924        163        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 1.2it/s 26.1s0.8ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.7it/s 5.7s2.8ss\n",
            "                   all         53       1295      0.894      0.883       0.92      0.513\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     68/100         0G      1.593     0.7114     0.7901        122        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 1.2it/s 26.2s0.8ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.7it/s 5.6s2.8ss\n",
            "                   all         53       1295      0.889       0.87      0.911      0.473\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     69/100         0G      1.581     0.6974     0.7972        159        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 1.0it/s 30.7s0.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.7it/s 5.7s2.8ss\n",
            "                   all         53       1295      0.885      0.875      0.914      0.505\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     70/100         0G      1.523     0.6644     0.7904        137        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 1.2it/s 26.3s0.8ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.7it/s 5.7s2.8ss\n",
            "                   all         53       1295        0.9       0.89       0.92      0.477\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     71/100         0G      1.484     0.6493     0.7946        228        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 1.2it/s 26.4s0.8ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.7it/s 5.6s2.8ss\n",
            "                   all         53       1295      0.893      0.892      0.925       0.54\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     72/100         0G      1.547     0.6733     0.7912        115        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 1.2it/s 25.9s0.8ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.7it/s 5.7s2.8ss\n",
            "                   all         53       1295      0.868      0.839      0.897      0.462\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     73/100         0G      1.583     0.6753      0.788         77        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 1.2it/s 25.3s0.8ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.7it/s 5.6s2.8ss\n",
            "                   all         53       1295      0.885      0.869      0.916      0.521\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     74/100         0G      1.543     0.6545     0.7912        177        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 1.2it/s 26.5s0.8ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.7it/s 5.8s2.8ss\n",
            "                   all         53       1295      0.878      0.863      0.905      0.483\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     75/100         0G      1.531     0.6537     0.7953        126        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 1.2it/s 25.8s0.8ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.7it/s 5.6s2.8ss\n",
            "                   all         53       1295      0.888      0.896      0.926      0.509\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     76/100         0G      1.518     0.6591     0.7918         99        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 1.2it/s 26.3s0.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.7it/s 5.6s2.8ss\n",
            "                   all         53       1295       0.86      0.844      0.892       0.45\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     77/100         0G      1.537     0.6916     0.7884         87        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 1.2it/s 25.7s0.8ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.7it/s 5.7s2.8ss\n",
            "                   all         53       1295      0.882      0.877      0.919      0.519\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     78/100         0G      1.512     0.6637     0.7894        234        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 1.0it/s 31.0s0.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.7it/s 5.7s2.8ss\n",
            "                   all         53       1295      0.894       0.88      0.919      0.526\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     79/100         0G      1.504     0.6663     0.7947        289        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 1.1it/s 27.5s0.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.7it/s 5.7s2.8ss\n",
            "                   all         53       1295      0.881      0.875      0.909      0.485\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     80/100         0G      1.496     0.6529     0.7908        159        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 1.2it/s 26.2s0.8ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.7it/s 5.5s2.7ss\n",
            "                   all         53       1295      0.893      0.886      0.926      0.509\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     81/100         0G      1.471     0.6482     0.7905        202        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 1.2it/s 25.4s0.8ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.7it/s 5.5s2.7ss\n",
            "                   all         53       1295      0.884      0.857       0.91      0.504\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     82/100         0G       1.46     0.6544     0.7884        172        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 1.2it/s 25.4s0.8ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.7it/s 5.6s2.8ss\n",
            "                   all         53       1295      0.885      0.871      0.917      0.504\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     83/100         0G      1.449     0.6327     0.7929        211        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 1.2it/s 25.1s0.8ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.7it/s 5.5s2.8ss\n",
            "                   all         53       1295      0.884      0.881      0.921      0.518\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     84/100         0G      1.496     0.6528     0.7892        181        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 1.2it/s 25.3s0.8ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.7it/s 5.5s2.7ss\n",
            "                   all         53       1295      0.896      0.876      0.927      0.532\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     85/100         0G      1.509     0.6474     0.7922         67        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 1.2it/s 25.4s0.8ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.7it/s 5.5s2.7ss\n",
            "                   all         53       1295      0.898      0.901      0.935      0.502\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     86/100         0G      1.516     0.6475     0.7972         96        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 1.2it/s 25.6s0.8ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.7it/s 5.6s2.8ss\n",
            "                   all         53       1295      0.873      0.876      0.913      0.514\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     87/100         0G      1.454     0.6213     0.7929        150        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 1.2it/s 25.4s0.8ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.7it/s 5.5s2.7ss\n",
            "                   all         53       1295      0.874      0.864      0.916      0.517\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     88/100         0G      1.475     0.6287     0.7876        256        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 1.2it/s 26.4s0.8ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.7it/s 5.5s2.7ss\n",
            "                   all         53       1295      0.894      0.877      0.923      0.533\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     89/100         0G      1.462     0.6542     0.7862        231        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 1.2it/s 25.7s0.8ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.7it/s 5.5s2.7ss\n",
            "                   all         53       1295      0.892      0.877      0.922      0.535\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     90/100         0G      1.455     0.6483       0.79        241        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 1.2it/s 25.4s0.8ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.7it/s 5.5s2.7ss\n",
            "                   all         53       1295      0.872      0.874      0.909       0.51\n",
            "Closing dataloader mosaic\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     91/100         0G      1.449      0.633     0.7882        109        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 1.2it/s 26.1s0.8ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.7it/s 5.6s2.8ss\n",
            "                   all         53       1295      0.886      0.883      0.919      0.521\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     92/100         0G      1.457     0.6326     0.7844        251        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 1.2it/s 26.3s0.8ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.7it/s 5.7s2.8ss\n",
            "                   all         53       1295      0.889       0.88      0.921      0.526\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     93/100         0G      1.427     0.6246      0.792        133        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 1.2it/s 26.3s0.8ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.7it/s 5.6s2.8ss\n",
            "                   all         53       1295      0.886       0.87      0.913      0.503\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     94/100         0G      1.435     0.6348     0.7897        198        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 1.2it/s 26.3s0.8ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.7it/s 5.6s2.8ss\n",
            "                   all         53       1295      0.886      0.875      0.917      0.521\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     95/100         0G      1.409     0.6276     0.7836        247        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 1.2it/s 26.3s0.8ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.7it/s 5.7s2.8ss\n",
            "                   all         53       1295      0.883      0.876      0.917      0.526\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     96/100         0G      1.441     0.6392     0.7857        121        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 1.2it/s 26.6s0.8ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.7it/s 5.6s2.8ss\n",
            "                   all         53       1295      0.873      0.874      0.909      0.515\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     97/100         0G       1.41     0.6155     0.7921        176        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 1.2it/s 26.3s0.8ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.7it/s 5.6s2.8ss\n",
            "                   all         53       1295      0.863      0.873      0.904      0.508\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     98/100         0G      1.423     0.6194     0.7878        137        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 1.2it/s 26.2s0.8ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.7it/s 5.6s2.8ss\n",
            "                   all         53       1295      0.867      0.869      0.908      0.506\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     99/100         0G      1.441     0.6296     0.7858        258        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 1.2it/s 26.2s0.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.7it/s 5.7s2.8ss\n",
            "                   all         53       1295      0.885      0.868      0.914      0.522\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    100/100         0G      1.406     0.6114     0.7862        330        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31/31 1.2it/s 26.4s0.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.7it/s 5.7s2.8ss\n",
            "                   all         53       1295      0.889      0.873      0.918      0.531\n",
            "\n",
            "100 epochs completed in 0.900 hours.\n",
            "Optimizer stripped from /Users/harshasathish/Desktop/MAI/ComputerVision/Portfolio1_new/output/models/waterfowl_detector/weights/last.pt, 6.2MB\n",
            "Optimizer stripped from /Users/harshasathish/Desktop/MAI/ComputerVision/Portfolio1_new/output/models/waterfowl_detector/weights/best.pt, 6.2MB\n",
            "\n",
            "Validating /Users/harshasathish/Desktop/MAI/ComputerVision/Portfolio1_new/output/models/waterfowl_detector/weights/best.pt...\n",
            "Ultralytics 8.3.227 ğŸš€ Python-3.13.2 torch-2.9.0 CPU (Apple M3 Pro)\n",
            "Model summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.6it/s 6.4s3.0ss\n",
            "                   all         53       1295      0.893      0.892      0.926       0.54\n",
            "Speed: 0.2ms preprocess, 102.1ms inference, 0.0ms loss, 0.1ms postprocess per image\n",
            "Results saved to \u001b[1m/Users/harshasathish/Desktop/MAI/ComputerVision/Portfolio1_new/output/models/waterfowl_detector\u001b[0m\n",
            "\n",
            "âœ“ Training complete!\n",
            "  Best model saved to: output/models/waterfowl_detector/weights/best.pt\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STEP 2: Model Training\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "device = 'cpu'\n",
        "\n",
        "# Load pretrained YOLOv8 model\n",
        "print(\"\\nâœ“ Loading YOLOv8n (nano) pretrained model...\")\n",
        "model = YOLO('yolov8n.pt')\n",
        "\n",
        "print(f\"\\nâœ“ Starting training...\")\n",
        "print(f\"  Epochs: {EPOCHS}\")\n",
        "print(f\"  Image size: {IMG_SIZE}\")\n",
        "print(f\"  Batch size: {BATCH_SIZE}\")\n",
        "print(f\"  Device: {device}\")\n",
        "\n",
        "# Train the model\n",
        "results = model.train(\n",
        "    data=str(yaml_path),\n",
        "    epochs=EPOCHS,\n",
        "    imgsz=IMG_SIZE,\n",
        "    batch=BATCH_SIZE,\n",
        "    device=device,\n",
        "    project=str(model_dir),\n",
        "    name='waterfowl_detector',\n",
        "    exist_ok=True,\n",
        "    hsv_h=0.015,\n",
        "    hsv_s=0.7,\n",
        "    hsv_v=0.4,\n",
        "    degrees=10,\n",
        "    translate=0.1,\n",
        "    scale=0.5,\n",
        "    fliplr=0.5,\n",
        "    flipud=0.0,\n",
        "    mosaic=0.0,\n",
        ")\n",
        "\n",
        "# Save best model path\n",
        "best_model_path = model_dir / 'waterfowl_detector' / 'weights' / 'best.pt'\n",
        "\n",
        "print(f\"\\nâœ“ Training complete!\")\n",
        "print(f\"  Best model saved to: {best_model_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGz5ejnpmWPU"
      },
      "source": [
        "# **10. Model Evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "p3EMEf9hmbRd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "STEP 3: Model Evaluation\n",
            "============================================================\n",
            "\n",
            "âœ“ Evaluating on test set...\n",
            "Ultralytics 8.3.227 ğŸš€ Python-3.13.2 torch-2.9.0 MPS (Apple M3 Pro)\n",
            "Model summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.1Â±0.0 ms, read: 1062.2Â±272.5 MB/s, size: 343.1 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/harshasathish/Desktop/MAI/ComputerVision/Portfolio1_new/output/yolo_dataset/test/labels... 54 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 54/54 3.8Kit/s 0.0s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /Users/harshasathish/Desktop/MAI/ComputerVision/Portfolio1_new/output/yolo_dataset/test/labels.cache\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.6it/s 6.6s2.3ss\n",
            "                   all         54       1651      0.919      0.915      0.948      0.571\n",
            "Speed: 24.1ms preprocess, 6.5ms inference, 0.0ms loss, 20.9ms postprocess per image\n",
            "Results saved to \u001b[1m/Users/harshasathish/Desktop/MAI/ComputerVision/Portfolio1_new/runs/detect/val7\u001b[0m\n",
            "\n",
            "âœ“ Evaluation Results:\n",
            "  mAP@50:    0.9478\n",
            "  mAP@50-95: 0.5707\n",
            "  Precision: 0.9186\n",
            "  Recall:    0.9155\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STEP 3: Model Evaluation\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Load the best model\n",
        "model = YOLO(str(best_model_path))\n",
        "device = 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
        "\n",
        "# Run validation on test set\n",
        "print(\"\\nâœ“ Evaluating on test set...\")\n",
        "\n",
        "metrics = model.val(\n",
        "    data=str(yaml_path),\n",
        "    split='test',\n",
        "    device=device\n",
        ")\n",
        "\n",
        "print(\"\\nâœ“ Evaluation Results:\")\n",
        "print(f\"  mAP@50:    {metrics.box.map50:.4f}\")\n",
        "print(f\"  mAP@50-95: {metrics.box.map:.4f}\")\n",
        "print(f\"  Precision: {metrics.box.mp:.4f}\")\n",
        "print(f\"  Recall:    {metrics.box.mr:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbhP9oaamhQR"
      },
      "source": [
        "# **11. Result Visualization**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "oQBxtsAvmh9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "STEP 4: Visualization\n",
            "============================================================\n",
            "\n",
            "âœ“ Analyzing 54 test images...\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STEP 4: Visualization\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "model = YOLO(str(best_model_path))\n",
        "device = 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
        "\n",
        "# Get test images\n",
        "test_img_dir = yolo_root / 'test' / 'images'\n",
        "test_label_dir = yolo_root / 'test' / 'labels'\n",
        "test_images = list(test_img_dir.glob('*.tif')) + list(test_img_dir.glob('*.jpg')) + list(test_img_dir.glob('*.png'))\n",
        "\n",
        "# Categories for visualization\n",
        "categories = {\n",
        "    'true_positives': [],\n",
        "    'false_negatives': [],\n",
        "    'false_positives': []\n",
        "}\n",
        "\n",
        "print(f\"\\nâœ“ Analyzing {len(test_images)} test images...\")\n",
        "\n",
        "# Run inference and categorize results\n",
        "for img_path in test_images:\n",
        "    # Load image\n",
        "    img = cv2.imread(str(img_path))\n",
        "    if img is None:\n",
        "        continue\n",
        "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Get predictions\n",
        "    results = model(img_path, device=device, verbose=False)\n",
        "    predictions = results[0].boxes\n",
        "\n",
        "    # Load ground truth\n",
        "    label_path = test_label_dir / f\"{img_path.stem}.txt\"\n",
        "    gt_boxes = []\n",
        "    if label_path.exists():\n",
        "        with open(label_path, 'r') as f:\n",
        "            for line in f:\n",
        "                parts = line.strip().split()\n",
        "                if len(parts) == 5:\n",
        "                    gt_boxes.append([float(x) for x in parts[1:]])\n",
        "\n",
        "    # Categorize based on predictions and ground truth\n",
        "    num_predictions = len(predictions)\n",
        "    num_ground_truth = len(gt_boxes)\n",
        "\n",
        "    if num_ground_truth > 0 and num_predictions > 0:\n",
        "        categories['true_positives'].append((img_path, img_rgb, predictions, gt_boxes))\n",
        "    elif num_ground_truth > 0 and num_predictions == 0:\n",
        "        categories['false_negatives'].append((img_path, img_rgb, predictions, gt_boxes))\n",
        "    elif num_ground_truth == 0 and num_predictions > 0:\n",
        "        categories['false_positives'].append((img_path, img_rgb, predictions, gt_boxes))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22Uh-S3rmoZX"
      },
      "source": [
        "# **12. Data Visualization Plots**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "djZYYsMom2Td"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "âœ“ Visualizing true_positives: 3 examples\n",
            "  Saved to: output/results/true_positives.png\n",
            "\n",
            "! No false_negatives found\n",
            "\n",
            "! No false_positives found\n",
            "\n",
            "âœ“ Visualization complete!\n",
            "\n",
            "============================================================\n",
            "PIPELINE COMPLETE!\n",
            "============================================================\n",
            "\n",
            "All outputs saved to: output/\n"
          ]
        }
      ],
      "source": [
        "num_examples = 3\n",
        "\n",
        "# Visualize each category\n",
        "for category_name, examples in categories.items():\n",
        "    if len(examples) == 0:\n",
        "        print(f\"\\n! No {category_name} found\")\n",
        "        continue\n",
        "\n",
        "    # Select random examples\n",
        "    selected = random.sample(examples, min(num_examples, len(examples)))\n",
        "\n",
        "    print(f\"\\nâœ“ Visualizing {category_name}: {len(selected)} examples\")\n",
        "\n",
        "    fig, axes = plt.subplots(1, len(selected), figsize=(5*len(selected), 5))\n",
        "    if len(selected) == 1:\n",
        "        axes = [axes]\n",
        "\n",
        "    # Plot each example\n",
        "    for idx, (img_path, img_rgb, predictions, gt_boxes) in enumerate(selected):\n",
        "        ax = axes[idx]\n",
        "        ax.imshow(img_rgb)\n",
        "\n",
        "        h, w = img_rgb.shape[:2]\n",
        "\n",
        "        # Draw ground truth boxes (green)\n",
        "        for box in gt_boxes:\n",
        "            x_center, y_center, width, height = box\n",
        "            x1 = int((x_center - width/2) * w)\n",
        "            y1 = int((y_center - height/2) * h)\n",
        "            x2 = int((x_center + width/2) * w)\n",
        "            y2 = int((y_center + height/2) * h)\n",
        "\n",
        "            rect = plt.Rectangle((x1, y1), x2-x1, y2-y1,\n",
        "                                fill=False, color='green', linewidth=2)\n",
        "            ax.add_patch(rect)\n",
        "\n",
        "        # Draw predictions (red) - WITHOUT labels\n",
        "        if len(predictions) > 0:\n",
        "            for box in predictions.xyxy:\n",
        "                x1, y1, x2, y2 = box.cpu().numpy()\n",
        "                rect = plt.Rectangle((x1, y1), x2-x1, y2-y1,\n",
        "                                    fill=False, color='red', linewidth=2)\n",
        "                ax.add_patch(rect)\n",
        "\n",
        "        ax.set_title(f\"{img_path.name}\", fontsize=10)\n",
        "        ax.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    save_path = results_dir / f'{category_name}.png'\n",
        "    plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
        "    print(f\"  Saved to: {save_path}\")\n",
        "    plt.close()\n",
        "\n",
        "print(f\"\\nâœ“ Visualization complete!\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"PIPELINE COMPLETE!\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\nAll outputs saved to: {OUTPUT_ROOT}/\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
